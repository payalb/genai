{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83434348-ddae-4167-8427-4bb50e797a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"selected_profile\": \"software engineer\"\n",
      "}\n",
      "```\n",
      "software engineer\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "import  re\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]= true\n",
    "os.environ[\"LANGCHAIN_ENTRYPOINT\"]= :H\n",
    "\n",
    "# Configure Gemini client\n",
    "genai.configure(api_key=\"AIz\")\n",
    "\n",
    "# Pydantic model for validation\n",
    "class ProfileRouter(BaseModel):\n",
    "    selected_profile: str = Field(description=\"One of [hr, software engineer, product manager]\")\n",
    "\n",
    "def llm_call_route(problem: str) -> str:\n",
    "    \"\"\"Selects which profile should solve the problem.\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a router. You must select ONE profile to solve the given problem.\n",
    "    Allowed profiles:\n",
    "    - hr\n",
    "    - software engineer\n",
    "    - product manager\n",
    "\n",
    "    Problem: {problem}\n",
    "\n",
    "    Respond ONLY in JSON with this format:\n",
    "    {{\n",
    "      \"selected_profile\": \"software engineer\"\n",
    "    }}\n",
    "\n",
    "    No markdown, no code fences, no explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    raw_text = response.text.strip()\n",
    "    print(raw_text)\n",
    "    # ðŸ”¹ Clean up code fences if Gemini adds them\n",
    "    if raw_text.startswith(\"```\"):\n",
    "        raw_text = re.sub(r\"^```[a-zA-Z]*\\n\", \"\", raw_text)  # remove opening fence\n",
    "        raw_text = raw_text.rstrip(\"`\")                      # remove closing fence\n",
    "\n",
    "    # ðŸ”¹ Parse JSON safely\n",
    "    try:\n",
    "        parsed = json.loads(raw_text)\n",
    "        validated = ProfileRouter(**parsed)\n",
    "        return validated.selected_profile\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid response: {raw_text}\") from e\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(llm_call_route(\"I need to fix this bug in our codebase\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffda5d-475d-42d4-9c71-899bce5426f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
