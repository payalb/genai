{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a027dc-43f9-4788-92f3-10f477b483bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bubble plot shows a positive correlation between area and population, with a cluster of data points concentrated in the lower left, indicating smaller areas with lower populations.  A subset of these points is enclosed by a polygon, suggesting a distinct group or cluster.  Outside this cluster, data points are more scattered, with some areas having significantly larger populations than others of similar size.  The different colors represent different categories (likely locations or groups), but no clear trend emerges between these categories and the area/population relationship.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] ='AIz'\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "\n",
    "# Read file as bytes\n",
    "with open(r\"C:\\Users\\payal bansal\\img1.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "\n",
    "# Convert to base64 string\n",
    "img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Create data URI\n",
    "img_data_uri = f\"data:image/png;base64,{img_b64}\"\n",
    "# Initialize Gemini multimodal model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Load your chart image (local file or URL)\n",
    "image_path = r\"C:\\Users\\payal bansal\\img1.png\"\n",
    "\n",
    "# Create multimodal input: text + image\n",
    "msg = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Summarize the key trends in this chart.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": img_data_uri}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get response\n",
    "response = llm.invoke([msg])\n",
    "print(response.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
